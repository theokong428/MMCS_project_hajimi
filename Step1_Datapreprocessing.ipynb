{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c12ae9ea",
   "metadata": {},
   "source": [
    "# Step1: Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef989f80",
   "metadata": {},
   "source": [
    "(Using Python 3.12.11 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d835e19",
   "metadata": {},
   "source": [
    "## 1.1. Combine Dataset\n",
    "\n",
    "From cyclehire-cleandata(saved in 'row data' folder), check the total numer and combined data in one file('merged_2018_2021.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf62778",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "file_list = sorted(glob.glob('raw_data/[2][0][1][8-9]_??.csv') + glob.glob('data_propress/raw_data/[2][0][2][0-1]_??.csv'))\n",
    "print(\"Total number：\", len(file_list))\n",
    "\n",
    "# combie(clolumn)\n",
    "df_all = pd.concat([pd.read_csv(f) for f in file_list], ignore_index=True)\n",
    "\n",
    "df_all.to_csv('merged_2018_2021.csv', index=False)\n",
    "\n",
    "print(\"output：merged_2018_2021.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3184e3e",
   "metadata": {},
   "source": [
    "## 1.2. Data Preprocessing\n",
    "\n",
    "(1) Clean trip data, correct timestamps, and remove abnormal records. \n",
    "\n",
    "(2) Extract date and hour features for each trip.\n",
    "\n",
    "(3) Identify weekend and weekday trips. \n",
    "\n",
    "(4) Construct hourly OD (Origin–Destination) flow between stations.  \n",
    "\n",
    "(5) Export processed OD data for further modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d597e1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read data\n",
    "df = pd.read_csv(\"merged_2018_2021.csv\")\n",
    "\n",
    "# Convert time fields to datetime format\n",
    "df['started_at'] = pd.to_datetime(df['started_at'], utc=True, errors='coerce')\n",
    "df['ended_at'] = pd.to_datetime(df['ended_at'], utc=True, errors='coerce')\n",
    "\n",
    "# Drop rows with invalid timestamps\n",
    "df = df.dropna(subset=['started_at', 'ended_at'])\n",
    "\n",
    "\n",
    "#Remove trips that start and end at the same station\n",
    "df = df[df['start_station_id'] != df['end_station_id']]\n",
    "\n",
    "# Keep trips with reasonable duration:\n",
    "# < 60 seconds → likely malfunction\n",
    "# > 12 hours → likely forgotten to return, not valid for demand estimation\n",
    "df = df[(df['duration'] > 60) & (df['duration'] < 12*3600)]\n",
    "\n",
    "\n",
    "# Extract date and hour features\n",
    "\n",
    "df['date'] = df['started_at'].dt.date\n",
    "df['hour'] = df['started_at'].dt.hour\n",
    "df['end_hour'] = df['ended_at'].dt.ceil('h').dt.hour\n",
    "\n",
    "# Ensure date is in datetime format\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Create weekend label: 0 = Monday, 6 = Sunday\n",
    "df['is_weekend'] = df['date'].dt.weekday >= 5\n",
    "\n",
    "# Convert weekend flag to categorical string label\n",
    "df['day_type'] = df['is_weekend'].map({False: '1', True: '0'})\n",
    "\n",
    "# Construct hourly OD flow\n",
    "od = df.groupby(\n",
    "    ['date', 'hour', 'end_hour','start_station_id', 'end_station_id','day_type']\n",
    ").size().reset_index(name='trips')\n",
    "\n",
    "# Save the result\n",
    "od.to_csv(\"od.csv\", index=False)\n",
    "\n",
    "od.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ef8548",
   "metadata": {},
   "source": [
    "## 1.3. Zero Flated Poisson Rediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e168cdae",
   "metadata": {},
   "source": [
    "Estimate hourly OD demand using a zero-inflated Poisson model in one day type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a42f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import poisson\n",
    "\n",
    "# Read 'od.csv' \n",
    "df = pd.read_csv(\"od.csv\")\n",
    "\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['start_station_id'] = df['start_station_id'].astype(str)\n",
    "df['end_station_id'] = df['end_station_id'].astype(str)\n",
    "\n",
    "#Zero-inflated Poisson prediction function\n",
    "def zip_predict(row):\n",
    "    pi = row['zero_rate']               # Zero-inflation rate\n",
    "    lambda_c = row['count_process_rate']  # Poisson rate for the count process\n",
    "\n",
    "    # Structural zero\n",
    "    if np.random.rand() < pi:\n",
    "        return 0\n",
    "\n",
    "    # Poisson count process\n",
    "    lam = max(lambda_c, 0)\n",
    "    return np.random.poisson(lam)\n",
    "\n",
    "\n",
    "# Repeat the ZIP process for each day_type separately\n",
    "for dt in sorted(df['day_type'].unique()):\n",
    "    print(f\"\\nday_type = {dt} \")\n",
    "\n",
    "    df_dt = df[df['day_type'] == dt].copy()\n",
    "\n",
    "    # Count number of days and preprocess\n",
    "    n_days = df_dt['date'].nunique()\n",
    "    print(\"days count=\", n_days)\n",
    "\n",
    "    daily_trips = df_dt.groupby(\n",
    "        ['date', 'hour', 'start_station_id', 'end_station_id']\n",
    "    )['trips'].sum().reset_index()\n",
    "\n",
    "    # Aggregate statistics\n",
    "    agg = daily_trips.groupby(['hour', 'start_station_id', 'end_station_id']).agg(\n",
    "        total_trips=('trips', 'sum'),\n",
    "        days_with_trips=('trips', lambda x: (x > 0).sum())\n",
    "    ).reset_index()\n",
    "\n",
    "    # Compute zero-related statistics\n",
    "    agg['days_with_zero_trips'] = n_days - agg['days_with_trips']\n",
    "    agg['zero_rate'] = agg['days_with_zero_trips'] / n_days      # π\n",
    "    agg['overall_avg_trips'] = agg['total_trips'] / n_days       # λ\n",
    "\n",
    "    # λ_c: Poisson rate for the count process\n",
    "    agg['count_process_rate'] = np.where(\n",
    "        agg['zero_rate'] < 1.0,\n",
    "        agg['overall_avg_trips'] / (1 - agg['zero_rate']),\n",
    "        0.0\n",
    "    )\n",
    "\n",
    "    #ZIP-based demand prediction\n",
    "    agg['demand_avg'] = agg['overall_avg_trips']\n",
    "    agg['demand_zip_poisson'] = agg.apply(zip_predict, axis=1)\n",
    "\n",
    "    # Integer demand from average (ceiling / 0.5 rounding)\n",
    "    agg['demand_up'] = agg['overall_avg_trips'].apply(\n",
    "        lambda x: int(x) if x.is_integer() else int(x) + 1\n",
    "    )\n",
    "    agg['demand_0.5'] = agg['overall_avg_trips'].round().astype(int)\n",
    "\n",
    "    # Export results\n",
    "    out_name = f\"od_hourly_zip_poisson_daytype_{dt}.csv\"\n",
    "    agg.to_csv(out_name, index=False)\n",
    "\n",
    "    print(f\"day_type={dt} output to: {out_name}\")\n",
    "    print(\n",
    "        agg[\n",
    "            [\n",
    "                'hour',\n",
    "                'start_station_id',\n",
    "                'end_station_id',\n",
    "                'demand_avg',\n",
    "                'zero_rate',\n",
    "                'demand_zip_poisson'\n",
    "            ]\n",
    "        ].head(10)\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Xpress",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
