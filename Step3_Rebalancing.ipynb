{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c209cdf",
   "metadata": {},
   "source": [
    "# Step 4: Rebalnacing Plan "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5a09c2",
   "metadata": {},
   "source": [
    "## 4.1 Processing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a57eb26",
   "metadata": {},
   "source": [
    "### 4.1.1 Get the result of bicycles balance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e897315",
   "metadata": {},
   "source": [
    "#### Input：\n",
    "\n",
    "    od_hourly_zip_poisson_daytype_1.csv\n",
    "       \n",
    "#### Output：\n",
    "\n",
    "    station_daily_balance_daytype_1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06cbf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read demand prediction file\n",
    "df = pd.read_csv(\"od_hourly_zip_poisson_daytype_1.csv\")\n",
    "demand_col = \"demand_zip_poisson\"\n",
    "\n",
    "# Aggregate departures\n",
    "borrow = (\n",
    "    df.groupby(\"start_station_id\")[demand_col]\n",
    "    .sum()\n",
    "    .rename(\"borrowed\")\n",
    ")\n",
    "\n",
    "# Aggregate returns\n",
    "returned = (\n",
    "    df.groupby(\"end_station_id\")[demand_col]\n",
    "    .sum()\n",
    "    .rename(\"returned\")\n",
    ")\n",
    "\n",
    "# Merge into station-level table\n",
    "station_balance = pd.concat([borrow, returned], axis=1).fillna(0)\n",
    "\n",
    "# Compute net flow\n",
    "station_balance[\"net\"] = station_balance[\"returned\"] - station_balance[\"borrowed\"]\n",
    "\n",
    "# Define move_in / move_out\n",
    "station_balance[\"move_out\"] = station_balance[\"net\"].apply(lambda x: x if x > 0 else 0)\n",
    "station_balance[\"move_in\"] = station_balance[\"net\"].apply(lambda x: -x if x < 0 else 0)\n",
    "\n",
    "# Reset index to obtain station_id column\n",
    "station_balance = station_balance.reset_index().rename(columns={\"index\":\"station_id\"})\n",
    "\n",
    "# Save results\n",
    "station_balance.to_csv(\"station_daily_balance_daytype_1.csv\", index=False)\n",
    "\n",
    "station_balance.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de49108",
   "metadata": {},
   "source": [
    "### 4.1.2 Combine data for caulating distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835a0d8b",
   "metadata": {},
   "source": [
    "#### Input：\n",
    "\n",
    "    station_daily_balance_daytype_1.csv \n",
    "    merged_2018_2021.csv      \n",
    "#### Output：\n",
    "\n",
    "    station_tasks.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e293d573",
   "metadata": {},
   "source": [
    " Merge station daily net flows, coordinates, and capacity into a single task table.\n",
    " \n",
    " Read daily net demand, join with station locations and capacity plan, filter invalid coordinates, and export a cleaned per-station dataset for visualization or further analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0c35d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read daily rebalancing results\n",
    "balance = pd.read_csv(\"station_daily_balance_daytype_1.csv\")\n",
    "# Keep only the required columns\n",
    "balance = balance[[\"station_id\", \"move_out\", \"net\",\"move_in\"]]\n",
    "\n",
    "\n",
    "# Extract station coordinates \n",
    "df = pd.read_csv(\"merged_2018_2021.csv\")\n",
    "\n",
    "# Extract start_station_id and its latitude/longitude\n",
    "loc = df[[\"start_station_id\", \"start_station_latitude\", \"start_station_longitude\"]].drop_duplicates()\n",
    "\n",
    "# Rename columns \n",
    "loc = loc.rename(columns={\n",
    "    \"start_station_id\": \"station_id\",\n",
    "    \"start_station_latitude\": \"latitude\",\n",
    "    \"start_station_longitude\": \"longitude\"\n",
    "})\n",
    "\n",
    "#  Extract initial stock x_i and capacity y_i from Minlimit_capacity_daytype_1.csv\n",
    "cap = pd.read_csv(\"Minlimit_capacity_daytype_1.csv\")\n",
    "\n",
    "cap = cap.rename(columns={\n",
    "    \"x_i\": \"initial_stock\",\n",
    "    \"y_i\": \"capacity\"\n",
    "})\n",
    "\n",
    "# Merge the three tables\n",
    "\n",
    "# Merge balance with location\n",
    "df_merge = balance.merge(loc, on=\"station_id\", how=\"left\")\n",
    "\n",
    "# Merge with capacity info\n",
    "df_merge = df_merge.merge(cap[[\"station_id\", \"initial_stock\", \"capacity\"]],\n",
    "                          on=\"station_id\", how=\"left\")\n",
    "\n",
    "\n",
    "#Remove stations with missing coordinates\n",
    "\n",
    "# Latitude/longitude are left-joined from loc; missing ones are NaN\n",
    "print(f\"Station count before dropping: {len(df_merge)}\")\n",
    "\n",
    "# Drop rows with latitude or longitude is NaN\n",
    "df_merge.dropna(subset=[\"latitude\", \"longitude\"], inplace=True)\n",
    "\n",
    "# Convert to numeric types, drop invalid values \n",
    "df_merge[\"latitude\"] = pd.to_numeric(df_merge[\"latitude\"], errors='coerce')\n",
    "df_merge[\"longitude\"] = pd.to_numeric(df_merge[\"longitude\"], errors='coerce')\n",
    "df_merge.dropna(subset=[\"latitude\", \"longitude\"], inplace=True)\n",
    "\n",
    "print(f\"Station count after dropping: {len(df_merge)}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Remove duplicate stations\n",
    "df_merge = df_merge.drop_duplicates(subset=[\"station_id\"], keep=\"first\")\n",
    "\n",
    "\n",
    "# Reorder columns\n",
    "df_merge = df_merge[[\n",
    "    \"station_id\",\n",
    "    \"latitude\",\n",
    "    \"longitude\",\n",
    "    \"initial_stock\",\n",
    "    \"capacity\",\n",
    "    \"net\",\n",
    "    \"move_out\",\n",
    "    \"move_in\"\n",
    "]]\n",
    "\n",
    "# Export the final station task file\n",
    "df_merge.to_csv(\"station_tasks.csv\", index=False)\n",
    "\n",
    "df_merge.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Xpress",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
